<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>EdgeAI on Tasdiqul Islam</title>
    <link>http://localhost:1313/tags/edgeai/</link>
    <description>Recent content in EdgeAI on Tasdiqul Islam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/edgeai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Efficient Multilingual Feature Extraction for Edge NLP</title>
      <link>http://localhost:1313/projects/effe/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/effe/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;llm-powered-feature-extraction-for-edge&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;LLM-Powered Feature Extraction for Edge
  &lt;a href=&#34;#llm-powered-feature-extraction-for-edge&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Paper under review&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/projects/effe/eval_effe.png&#34; alt=&#34;Pareto Frontier&#34;&gt;&lt;/p&gt;
&lt;p&gt;This research introduces a novel approach for deploying multilingual NLP on edge devices by rethinking the role of large language models. Instead of running full LLM inference, the framework leverages them as static feature repositories, bypassing the computationally expensive transformer stack.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
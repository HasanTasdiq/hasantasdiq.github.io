<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on S. M. Hasan</title>
    <link>https://numan947.github.io/tags/llm/</link>
    <description>Recent content in LLM on S. M. Hasan</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://numan947.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Efficient Multilingual Feature Extraction for Edge NLP</title>
      <link>https://numan947.github.io/projects/effe/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://numan947.github.io/projects/effe/</guid>
      <description>&lt;h1 id=&#34;llm-powered-feature-extraction-for-edge&#34;&gt;LLM-Powered Feature Extraction for Edge&lt;/h1&gt;&#xA;&lt;p&gt;&lt;em&gt;Paper under review&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://numan947.github.io/projects/effe/eval_effe.png&#34; alt=&#34;Pareto Frontier&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;This research introduces a novel approach for deploying multilingual NLP on edge devices by rethinking the role of large language models. Instead of running full LLM inference, the framework leverages them as static feature repositories, bypassing the computationally expensive transformer stack.&lt;/p&gt;&#xA;&lt;p&gt;The method enables a tunable efficiency hierarchy, from ultra-efficient static embeddings to enhanced hybrid features via lightweight distillation. By using multilingual LLMs as a unified source, it eliminates the complexity of managing language-specific pipelines, providing a scalable path to on-device intelligence without the traditional overhead.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

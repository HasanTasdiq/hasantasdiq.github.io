<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Tasdiqul Islam</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Home on Tasdiqul Islam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://localhost:1313/landing/welcome/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/landing/welcome/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;s-mahmudul-hasan&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;S Mahmudul Hasan
  &lt;a href=&#34;#s-mahmudul-hasan&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Ph.D. Student in Computer Science, Tulane University, New Orleans, Louisiana&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Research focus:&lt;/strong&gt; Convergence of AI and Edge Computing, Systems&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/bio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/bio/</guid>
      <description>&lt;p&gt;I bridge the gap between quantum theory and scalable systems. Currently pursuing my Ph.D. at UT Arlington (Expecting to graduate in May&#39;2026), I use Deep Reinforcement Learning to solve routing bottlenecks in quantum networks. My research creates adaptive, fidelity-aware algorithms that prioritize real-world throughput, backed by my 3+ years of industry engineering experience&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Education</title>
      <link>http://localhost:1313/about/education/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/education/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ph.D. in Computer Science and Engineering&lt;/strong&gt;, University of Texas at Arlington, Texas, USA, Expected 2026&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B.Sc. in Computer Science and Engineering&lt;/strong&gt;, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh, 2019&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>News</title>
      <link>http://localhost:1313/landing/news/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/landing/news/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;latest-news&#34; --&gt;

&lt;h2 class=&#34;header-anchor-wrapper&#34;&gt;Latest News
  &lt;a href=&#34;#latest-news&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;üì¢ &lt;em&gt;Sept 2025&lt;/em&gt;: Presented our latest paper at ACM CCS.&lt;/li&gt;
&lt;li&gt;üìù &lt;em&gt;Aug 2025&lt;/em&gt;: Blogged about symbolic execution and real-world testing.&lt;/li&gt;
&lt;li&gt;üéì &lt;em&gt;May 2025&lt;/em&gt;: Completed PhD candidacy exam successfully.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Quick Links</title>
      <link>http://localhost:1313/landing/quicklinks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/landing/quicklinks/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/about/&#34;&gt;About&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/research/&#34;&gt;Research&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/publications/&#34;&gt;Publications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://localhost:1313/posts/&#34;&gt;Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/about/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/contact/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Email&lt;/strong&gt;: txi7184 [at] mavs.uta.edu&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Office&lt;/strong&gt;:  900 S Center St, Arlington, TX 76010&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LinkedIn&lt;/strong&gt;: &lt;a href=&#34;https://www.linkedin.com/in/tasdiqul-islam-07b41b16a/&#34;&gt;linkedin.com/in/tasdiqul-islam-07b41b16a&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href=&#34;https://github.com/HasanTasdiq&#34;&gt;github.com/HasanTasdiq&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>Find Me Online</title>
      <link>http://localhost:1313/landing/social/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/landing/social/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.linkedin.com/in/yourprofile&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yourusername&#34;&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=XXXXX&#34;&gt;Google Scholar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>RL Notes: Huggin Face RL Course</title>
      <link>http://localhost:1313/posts/hfrl-1/</link>
      <pubDate>Fri, 10 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/hfrl-1/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;hfrl-unit-1&#34; --&gt;

&lt;h2 class=&#34;header-anchor-wrapper&#34;&gt;&lt;a href=&#34;https://huggingface.co/learn/deep-rl-course/en/unit1&#34;&gt;HFRL Unit-1&lt;/a&gt;
  &lt;a href=&#34;#hfrl-unit-1&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h2&gt;

&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;summary&#34; --&gt;

&lt;h3 class=&#34;header-anchor-wrapper&#34;&gt;Summary
  &lt;a href=&#34;#summary&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reinforcement Learning is a method where an agent learns by interacting with its environment, using trial and error and feedback from rewards.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Attention-Free Transformer: Escaping the Quadratic Bottleneck</title>
      <link>http://localhost:1313/posts/aft-1/</link>
      <pubDate>Sun, 28 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/aft-1/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;attention-free-transformer-escaping-the-quadratic-bottleneck&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;Attention-Free Transformer: Escaping the Quadratic Bottleneck
  &lt;a href=&#34;#attention-free-transformer-escaping-the-quadratic-bottleneck&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;How AFT rethinks attention to achieve linear complexity while preserving performance&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The Transformer architecture revolutionized AI, but its self-attention mechanism comes with a fundamental limitation: quadratic complexity $\mathcal{O}(n^2)$ with sequence length. This makes processing long sequences computationally prohibitive. The Attention-Free Transformer (AFT) emerges as an elegant solution that maintains strong performance while achieving linear complexity.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Demystifying Transformers: Attention, Multi-Head Magic, and the Math Behind the Revolution</title>
      <link>http://localhost:1313/posts/transformers-1/</link>
      <pubDate>Sat, 27 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/transformers-1/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;demystifying-transformers-attention-multi-head-magic-and-the-math-behind-the-revolution&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;Demystifying Transformers: Attention, Multi-Head Magic, and the Math Behind the Revolution
  &lt;a href=&#34;#demystifying-transformers-attention-multi-head-magic-and-the-math-behind-the-revolution&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;From single head to multi-head attention - understanding the architectural breakthrough that changed AI forever&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The Transformer architecture, introduced in the seminal &amp;ldquo;Attention Is All You Need&amp;rdquo; paper, revolutionized natural language processing by replacing recurrent networks with a purely attention-based approach. At its heart lies the self-attention mechanism - a powerful way for models to understand relationships between all words in a sequence simultaneously.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Demystifying RNNs: A Deep Dive into Dimensions and Parameters</title>
      <link>http://localhost:1313/posts/rnn-1/</link>
      <pubDate>Fri, 26 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/posts/rnn-1/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;demystifying-rnns-a-deep-dive-into-dimensions-and-parameters&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;Demystifying RNNs: A Deep Dive into Dimensions and Parameters
  &lt;a href=&#34;#demystifying-rnns-a-deep-dive-into-dimensions-and-parameters&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Understanding what really happens inside Recurrent Neural Networks&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When learning about Recurrent Neural Networks (RNNs), many tutorials focus on the high-level concept of &amp;ldquo;memory&amp;rdquo; but gloss over the practical details of how they actually work. As someone who struggled with these details, I want to share the insights that finally made RNNs click for me.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Efficient Multilingual Feature Extraction for Edge NLP</title>
      <link>http://localhost:1313/projects/effe/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/effe/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;llm-powered-feature-extraction-for-edge&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;LLM-Powered Feature Extraction for Edge
  &lt;a href=&#34;#llm-powered-feature-extraction-for-edge&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Paper under review&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/projects/effe/eval_effe.png&#34; alt=&#34;Pareto Frontier&#34;&gt;&lt;/p&gt;
&lt;p&gt;This research introduces a novel approach for deploying multilingual NLP on edge devices by rethinking the role of large language models. Instead of running full LLM inference, the framework leverages them as static feature repositories, bypassing the computationally expensive transformer stack.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Evaluating Fuzzers on Cryptographic Protocols</title>
      <link>http://localhost:1313/projects/fuzzeval/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/fuzzeval/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;evaluating-fuzzers-on-cryptographic-protocols&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;Evaluating Fuzzers on Cryptographic Protocols
  &lt;a href=&#34;#evaluating-fuzzers-on-cryptographic-protocols&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Paper accepted at SBFT 2025 Workshop (co-located with ICSE 2025)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/projects/fuzzeval/workflow_csfuzz.png&#34; alt=&#34;Workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;General-purpose fuzzers often struggle to identify vulnerabilities in cryptographic libraries because they cannot generate inputs that satisfy strict protocol validations. This study evaluates modern fuzzers on their ability to produce &lt;strong&gt;context-sensitive inputs&lt;/strong&gt; for PKCS#1-v1.5 signature verification. Our findings show that &lt;strong&gt;semantic awareness&lt;/strong&gt;‚Äîunderstanding complex relationships between input fields‚Äîis more critical than code coverage for testing these security-critical implementations.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SeQR: Secure and Simple Enterprise Wi-Fi Configuration</title>
      <link>http://localhost:1313/projects/seqr/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/seqr/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;seqr-secure-and-simple-enterprise-wi-fi-configuration&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;SeQR: Secure and Simple Enterprise Wi-Fi Configuration
  &lt;a href=&#34;#seqr-secure-and-simple-enterprise-wi-fi-configuration&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Paper accepted at ACM Conference on Human Factors in Computing Systems (CHI) 2025&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/projects/seqr/seqr_workflow.png&#34; alt=&#34;SeQR Workflow&#34;&gt;&lt;/p&gt;
&lt;p&gt;Enterprise Wi-Fi configuration remains vulnerable to &amp;ldquo;Evil Twin&amp;rdquo; attacks due to complex client-side setup requirements that often lead to security misconfigurations. This paper introduces SeQR, a new configurator that uses QR codes to fully automate enterprise Wi-Fi setup through existing authenticated channels. By removing insecure configuration options and simplifying certificate validation, SeQR ensures users automatically establish secure connections without technical expertise. User studies demonstrate that SeQR significantly improves usability while eliminating the misconfigurations that enable credential theft attacks.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Socioeconomic Factors and Global Disease Outbreaks</title>
      <link>http://localhost:1313/projects/diseaseoutbreaks/</link>
      <pubDate>Thu, 25 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/diseaseoutbreaks/</guid>
      <description>&lt;!-- end-chunk --&gt;
&lt;!-- begin-chunk data-anchor=&#34;socioeconomic-factors-and-global-disease-outbreaks&#34; --&gt;

&lt;h1 class=&#34;header-anchor-wrapper&#34;&gt;Socioeconomic Factors and Global Disease Outbreaks
  &lt;a href=&#34;#socioeconomic-factors-and-global-disease-outbreaks&#34; class=&#34;header-anchor-link&#34;&gt;
&lt;svg
    xmlns=&#34;http://www.w3.org/2000/svg&#34;
    width=&#34;1rem&#34; height=&#34;1rem&#34; viewBox=&#34;0 0 24 24&#34; fill=&#34;none&#34;
    stroke=&#34;currentColor&#34; stroke-width=&#34;2&#34; stroke-linecap=&#34;round&#34;
    stroke-linejoin=&#34;round&#34;&gt;
    &lt;line x1=&#34;4&#34; y1=&#34;9&#34; x2=&#34;20&#34; y2=&#34;9&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;4&#34; y1=&#34;15&#34; x2=&#34;20&#34; y2=&#34;15&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;10&#34; y1=&#34;3&#34; x2=&#34;8&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;&lt;line x1=&#34;16&#34; y1=&#34;3&#34; x2=&#34;14&#34; y2=&#34;21&#34;&gt;&lt;/line&gt;
&lt;/svg&gt;

&lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;Paper accepted at the Proceedings of the 5th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies, 2022&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This large-scale study analyzes the relationship between socioeconomic conditions and infectious disease outbreaks worldwide. By examining data from 72 diseases over 23 years, the research identifies significant correlations between 192 socioeconomic indicators and outbreak characteristics. The findings reveal that factors like healthcare access, education levels, employment patterns, and population demographics consistently correlate with specific outbreak types and transmission methods. These insights can enhance disease surveillance systems by incorporating socioeconomic data for more accurate outbreak prediction and targeted public health interventions.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>